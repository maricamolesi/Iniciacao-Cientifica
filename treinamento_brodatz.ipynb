{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "treinamento_brodatz.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYJ3JSkFIRaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENwc28IgB_k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "data_dir = '/content/drive/My Drive/ProjetoIC/Brodatz_trainval_corroido1'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gODpiqpLjhxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKjNsuMI3PfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM2N5GwLMAkP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc0cf46b-2b05-4887-d3bb-21828244f818"
      },
      "source": [
        "#Finetuning the convnett\n",
        "model_ft = models.resnet50(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.002, momentum=0.8)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=9, gamma=0.6)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 4.8437 Acc: 0.0101\n",
            "val Loss: 4.1498 Acc: 0.0608\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 4.3166 Acc: 0.0417\n",
            "val Loss: 3.4092 Acc: 0.1216\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 3.9059 Acc: 0.0845\n",
            "val Loss: 2.9353 Acc: 0.2489\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 3.5736 Acc: 0.1295\n",
            "val Loss: 2.7264 Acc: 0.2635\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 3.2255 Acc: 0.1847\n",
            "val Loss: 2.6047 Acc: 0.3198\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 2.9910 Acc: 0.2342\n",
            "val Loss: 1.8900 Acc: 0.4268\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 2.8114 Acc: 0.2725\n",
            "val Loss: 2.0507 Acc: 0.4414\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 2.6987 Acc: 0.2815\n",
            "val Loss: 1.8765 Acc: 0.4887\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 2.5377 Acc: 0.3243\n",
            "val Loss: 1.9124 Acc: 0.4505\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 2.2268 Acc: 0.3975\n",
            "val Loss: 1.5017 Acc: 0.5698\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 2.1067 Acc: 0.4324\n",
            "val Loss: 1.3955 Acc: 0.5721\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 2.0169 Acc: 0.4313\n",
            "val Loss: 1.2542 Acc: 0.6160\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 2.0041 Acc: 0.4403\n",
            "val Loss: 1.4472 Acc: 0.5721\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 1.9621 Acc: 0.4538\n",
            "val Loss: 1.3468 Acc: 0.5901\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 1.7773 Acc: 0.5113\n",
            "val Loss: 1.3328 Acc: 0.6070\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 1.7935 Acc: 0.5011\n",
            "val Loss: 1.2003 Acc: 0.6464\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 1.7183 Acc: 0.5270\n",
            "val Loss: 1.2385 Acc: 0.6453\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 1.7228 Acc: 0.5180\n",
            "val Loss: 1.2192 Acc: 0.6453\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 1.5093 Acc: 0.5878\n",
            "val Loss: 1.0829 Acc: 0.6858\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 1.4626 Acc: 0.6126\n",
            "val Loss: 0.8978 Acc: 0.7286\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 1.4413 Acc: 0.6059\n",
            "val Loss: 0.9876 Acc: 0.7027\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 1.3886 Acc: 0.6115\n",
            "val Loss: 0.8275 Acc: 0.7354\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 1.2859 Acc: 0.6329\n",
            "val Loss: 0.9477 Acc: 0.7252\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 1.2373 Acc: 0.6577\n",
            "val Loss: 0.9349 Acc: 0.7342\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 1.2660 Acc: 0.6351\n",
            "val Loss: 0.9214 Acc: 0.7218\n",
            "\n",
            "Training complete in 6m 29s\n",
            "Best val Acc: 0.735360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd4rO1dXLyNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c7b7f1b-0f17-4f63-9c73-1464fb661ca6"
      },
      "source": [
        "#ConvNet as fixed feature extractor\n",
        "\n",
        "model_conv = models.resnet50(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.4)\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 5.1358 Acc: 0.0123\n",
            "val Loss: 5.1875 Acc: 0.0090\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 4.8172 Acc: 0.0325\n",
            "val Loss: 4.4672 Acc: 0.0224\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 4.4839 Acc: 0.0694\n",
            "val Loss: 3.9208 Acc: 0.0907\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 4.2795 Acc: 0.0817\n",
            "val Loss: 4.4787 Acc: 0.0437\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 4.0755 Acc: 0.1209\n",
            "val Loss: 3.7247 Acc: 0.1265\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 4.0112 Acc: 0.1310\n",
            "val Loss: 3.4891 Acc: 0.1736\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 3.9013 Acc: 0.1389\n",
            "val Loss: 3.2290 Acc: 0.2128\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 3.5298 Acc: 0.1960\n",
            "val Loss: 2.9067 Acc: 0.3281\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 3.4020 Acc: 0.2161\n",
            "val Loss: 2.9712 Acc: 0.2576\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 3.3613 Acc: 0.2240\n",
            "val Loss: 2.9247 Acc: 0.2844\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 3.3471 Acc: 0.2105\n",
            "val Loss: 2.8379 Acc: 0.2934\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 3.3354 Acc: 0.2262\n",
            "val Loss: 2.7769 Acc: 0.3247\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 3.2854 Acc: 0.2475\n",
            "val Loss: 2.8019 Acc: 0.3147\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 3.2923 Acc: 0.2531\n",
            "val Loss: 2.7815 Acc: 0.3124\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 3.0767 Acc: 0.2867\n",
            "val Loss: 2.5590 Acc: 0.3774\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 3.1051 Acc: 0.2945\n",
            "val Loss: 2.6788 Acc: 0.3505\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 3.1200 Acc: 0.2766\n",
            "val Loss: 2.6342 Acc: 0.3527\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 3.1375 Acc: 0.2620\n",
            "val Loss: 2.6975 Acc: 0.3359\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 3.0658 Acc: 0.3169\n",
            "val Loss: 2.4619 Acc: 0.4087\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 3.0528 Acc: 0.3113\n",
            "val Loss: 2.5335 Acc: 0.3942\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 3.0157 Acc: 0.3102\n",
            "val Loss: 2.5931 Acc: 0.3606\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 3.0624 Acc: 0.3303\n",
            "val Loss: 2.4498 Acc: 0.4043\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 2.9217 Acc: 0.3606\n",
            "val Loss: 2.4311 Acc: 0.3875\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 2.9601 Acc: 0.3471\n",
            "val Loss: 2.5758 Acc: 0.3807\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 2.9439 Acc: 0.3639\n",
            "val Loss: 2.4418 Acc: 0.4132\n",
            "\n",
            "Training complete in 3m 31s\n",
            "Best val Acc: 0.413214\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}