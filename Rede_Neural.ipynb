{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "treinamento_brodatz.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1E9_82e8KIeC0L-vCHMDViWLEyNIqtdDh",
      "authorship_tag": "ABX9TyMAR1cyytIF57YIdiVj77k7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maricamolesi/Iniciacao-Cientifica/blob/master/Rede_Neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYJ3JSkFIRaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENwc28IgB_k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/My Drive/ProjetoIC/trainval_v10gamma001int20'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=12,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gODpiqpLjhxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM2N5GwLMAkP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8221cedc-31dc-4679-f443-c1429607f5da"
      },
      "source": [
        "#Finetuning the convnett\n",
        "model_ft = models.resnet101(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.002, momentum=0.8)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=9, gamma=0.6)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/34\n",
            "----------\n",
            "train Loss: 4.3972 Acc: 0.1166\n",
            "val Loss: 3.2149 Acc: 0.4502\n",
            "\n",
            "Epoch 1/34\n",
            "----------\n",
            "train Loss: 2.9626 Acc: 0.4294\n",
            "val Loss: 1.5496 Acc: 0.7727\n",
            "\n",
            "Epoch 2/34\n",
            "----------\n",
            "train Loss: 1.8819 Acc: 0.6334\n",
            "val Loss: 0.8819 Acc: 0.7951\n",
            "\n",
            "Epoch 3/34\n",
            "----------\n",
            "train Loss: 1.3140 Acc: 0.7220\n",
            "val Loss: 0.5837 Acc: 0.8511\n",
            "\n",
            "Epoch 4/34\n",
            "----------\n",
            "train Loss: 1.0211 Acc: 0.7668\n",
            "val Loss: 0.4329 Acc: 0.8947\n",
            "\n",
            "Epoch 5/34\n",
            "----------\n",
            "train Loss: 0.7885 Acc: 0.8352\n",
            "val Loss: 0.3540 Acc: 0.9093\n",
            "\n",
            "Epoch 6/34\n",
            "----------\n",
            "train Loss: 0.6876 Acc: 0.8386\n",
            "val Loss: 0.3248 Acc: 0.9160\n",
            "\n",
            "Epoch 7/34\n",
            "----------\n",
            "train Loss: 0.5659 Acc: 0.8700\n",
            "val Loss: 0.2608 Acc: 0.9250\n",
            "\n",
            "Epoch 8/34\n",
            "----------\n",
            "train Loss: 0.5442 Acc: 0.8722\n",
            "val Loss: 0.2241 Acc: 0.9362\n",
            "\n",
            "Epoch 9/34\n",
            "----------\n",
            "train Loss: 0.4307 Acc: 0.9013\n",
            "val Loss: 0.1908 Acc: 0.9530\n",
            "\n",
            "Epoch 10/34\n",
            "----------\n",
            "train Loss: 0.4295 Acc: 0.8957\n",
            "val Loss: 0.1750 Acc: 0.9574\n",
            "\n",
            "Epoch 11/34\n",
            "----------\n",
            "train Loss: 0.3365 Acc: 0.9271\n",
            "val Loss: 0.1654 Acc: 0.9586\n",
            "\n",
            "Epoch 12/34\n",
            "----------\n",
            "train Loss: 0.3388 Acc: 0.9283\n",
            "val Loss: 0.1511 Acc: 0.9630\n",
            "\n",
            "Epoch 13/34\n",
            "----------\n",
            "train Loss: 0.3090 Acc: 0.9372\n",
            "val Loss: 0.1841 Acc: 0.9474\n",
            "\n",
            "Epoch 14/34\n",
            "----------\n",
            "train Loss: 0.3191 Acc: 0.9305\n",
            "val Loss: 0.1514 Acc: 0.9619\n",
            "\n",
            "Epoch 15/34\n",
            "----------\n",
            "train Loss: 0.3013 Acc: 0.9294\n",
            "val Loss: 0.1403 Acc: 0.9642\n",
            "\n",
            "Epoch 16/34\n",
            "----------\n",
            "train Loss: 0.2672 Acc: 0.9417\n",
            "val Loss: 0.1472 Acc: 0.9586\n",
            "\n",
            "Epoch 17/34\n",
            "----------\n",
            "train Loss: 0.2509 Acc: 0.9473\n",
            "val Loss: 0.1590 Acc: 0.9608\n",
            "\n",
            "Epoch 18/34\n",
            "----------\n",
            "train Loss: 0.2286 Acc: 0.9540\n",
            "val Loss: 0.1453 Acc: 0.9653\n",
            "\n",
            "Epoch 19/34\n",
            "----------\n",
            "train Loss: 0.2292 Acc: 0.9428\n",
            "val Loss: 0.1373 Acc: 0.9664\n",
            "\n",
            "Epoch 20/34\n",
            "----------\n",
            "train Loss: 0.2247 Acc: 0.9507\n",
            "val Loss: 0.1201 Acc: 0.9675\n",
            "\n",
            "Epoch 21/34\n",
            "----------\n",
            "train Loss: 0.2566 Acc: 0.9529\n",
            "val Loss: 0.1271 Acc: 0.9653\n",
            "\n",
            "Epoch 22/34\n",
            "----------\n",
            "train Loss: 0.2195 Acc: 0.9574\n",
            "val Loss: 0.1342 Acc: 0.9664\n",
            "\n",
            "Epoch 23/34\n",
            "----------\n",
            "train Loss: 0.2310 Acc: 0.9473\n",
            "val Loss: 0.1268 Acc: 0.9698\n",
            "\n",
            "Epoch 24/34\n",
            "----------\n",
            "train Loss: 0.1958 Acc: 0.9630\n",
            "val Loss: 0.1204 Acc: 0.9698\n",
            "\n",
            "Epoch 25/34\n",
            "----------\n",
            "train Loss: 0.1816 Acc: 0.9675\n",
            "val Loss: 0.1270 Acc: 0.9675\n",
            "\n",
            "Epoch 26/34\n",
            "----------\n",
            "train Loss: 0.1818 Acc: 0.9630\n",
            "val Loss: 0.1282 Acc: 0.9664\n",
            "\n",
            "Epoch 27/34\n",
            "----------\n",
            "train Loss: 0.1703 Acc: 0.9720\n",
            "val Loss: 0.1311 Acc: 0.9653\n",
            "\n",
            "Epoch 28/34\n",
            "----------\n",
            "train Loss: 0.1807 Acc: 0.9641\n",
            "val Loss: 0.1206 Acc: 0.9675\n",
            "\n",
            "Epoch 29/34\n",
            "----------\n",
            "train Loss: 0.1801 Acc: 0.9652\n",
            "val Loss: 0.1110 Acc: 0.9698\n",
            "\n",
            "Epoch 30/34\n",
            "----------\n",
            "train Loss: 0.1802 Acc: 0.9664\n",
            "val Loss: 0.1014 Acc: 0.9742\n",
            "\n",
            "Epoch 31/34\n",
            "----------\n",
            "train Loss: 0.1757 Acc: 0.9709\n",
            "val Loss: 0.1110 Acc: 0.9731\n",
            "\n",
            "Epoch 32/34\n",
            "----------\n",
            "train Loss: 0.1628 Acc: 0.9686\n",
            "val Loss: 0.1104 Acc: 0.9731\n",
            "\n",
            "Epoch 33/34\n",
            "----------\n",
            "train Loss: 0.1414 Acc: 0.9742\n",
            "val Loss: 0.1084 Acc: 0.9742\n",
            "\n",
            "Epoch 34/34\n",
            "----------\n",
            "train Loss: 0.1668 Acc: 0.9630\n",
            "val Loss: 0.1095 Acc: 0.9742\n",
            "\n",
            "Training complete in 13m 7s\n",
            "Best val Acc: 0.974244\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}