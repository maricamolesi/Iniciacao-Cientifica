{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rede-Neural.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1E9_82e8KIeC0L-vCHMDViWLEyNIqtdDh",
      "authorship_tag": "ABX9TyO3oVsIogefL6odv60oW+iQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maricamolesi/Iniciacao-Cientifica/blob/master/Rede_Neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TtgIm1ybLTX",
        "colab_type": "text"
      },
      "source": [
        "Neste notebook foi utilizado o banco de imagens Brodatz 128x128 contendo 1776 imagens de textura, com leve corrosão (pelo código dos Automâtos Celulares; parâmetros v = 1, gamma = 0.01 e 30 iterações). O conjunto já estava dividido em pastas de treino e validação, feito na proporção meio a meio de forma aleatória.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYJ3JSkFIRaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "# Modified: Mariana Camolesi\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENwc28IgB_k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/My Drive/ProjetoIC/trainval_v10gamma001int30'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=10, shuffle=True, num_workers=5) \n",
        "                for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gODpiqpLjhxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "           \n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM2N5GwLMAkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finetuning the convnet\n",
        "#Load a pretrained model (Resnet50) and reset final fully connected layer.\n",
        "\n",
        "model_ft = models.resnet50(pretrained=True)\n",
        "\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "# The size of each output sample is len(class_names)\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# All parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.002, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.5 every 9 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=9, gamma=0.5)\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHqEFKDTeRLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "b5437d4c-bfd3-4578-f757-24052fa6c1af"
      },
      "source": [
        "#Train and evaluate\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.1209 Acc: 0.9752\n",
            "val Loss: 0.0950 Acc: 0.9775\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.1809 Acc: 0.9583\n",
            "val Loss: 0.0966 Acc: 0.9764\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.1275 Acc: 0.9730\n",
            "val Loss: 0.0975 Acc: 0.9707\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.1105 Acc: 0.9775\n",
            "val Loss: 0.0884 Acc: 0.9775\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.1163 Acc: 0.9730\n",
            "val Loss: 0.0855 Acc: 0.9809\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1249 Acc: 0.9696\n",
            "val Loss: 0.0956 Acc: 0.9752\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1250 Acc: 0.9741\n",
            "val Loss: 0.0865 Acc: 0.9786\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1064 Acc: 0.9809\n",
            "val Loss: 0.0894 Acc: 0.9809\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1202 Acc: 0.9775\n",
            "val Loss: 0.0866 Acc: 0.9786\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1160 Acc: 0.9741\n",
            "val Loss: 0.0916 Acc: 0.9752\n",
            "\n",
            "Training complete in 5m 40s\n",
            "Best val Acc: 0.980856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_9idqmEx3mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save trained model\n",
        "torch.save(model_ft, \"/content/drive/My Drive/ProjetoIC/Rede-Neural.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
